{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For learning purpose I am implementing word2vec using tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw= 'He is the king. The king is royal. She is the royal queen'\n",
    "\n",
    "corpus_raw=corpus_raw.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get unique words for vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in word_tokenize(corpus_raw) if word != '.'] #ignoring DOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(words)\n",
    "\n",
    "vocab_size = len(words)\n",
    "\n",
    "word2int = {o:i for i,o in enumerate(words)};\n",
    "int2word = {i:o for i,o in enumerate(words)};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences =[sentence.split() for sentence in corpus_raw.split('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he', 'is', 'the', 'king'],\n",
       " ['the', 'king', 'is', 'royal'],\n",
       " ['she', 'is', 'the', 'royal', 'queen']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to get bi-grams for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "\n",
    "WIN_LEN =2;\n",
    "\n",
    "for sentence in sentences :\n",
    "    for word_idx, word in enumerate(sentence):\n",
    "        for nb_word in sentence[max(0,word_idx-WIN_LEN) : min(word_idx\n",
    "                    +WIN_LEN,len(sentence))+1]:\n",
    "            if nb_word != word:\n",
    "                data.append([word,nb_word])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he', 'is'],\n",
       " ['he', 'the'],\n",
       " ['is', 'he'],\n",
       " ['is', 'the'],\n",
       " ['is', 'king'],\n",
       " ['the', 'he']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([to_categorical(word2int[a[0]],vocab_size) for a in data])\n",
    "y_train = np.array([to_categorical(word2int[a[1]],vocab_size) for a in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 7), (34, 7))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing tensorflow model to train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,shape=(None,vocab_size),name='input_word')\n",
    "y=tf.placeholder(tf.float32,shape=(None,vocab_size),name='pred_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(7)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 5; # This variable changes based on our vocab_size\n",
    "#This is we are giving to the next following layer because the output of \n",
    "#this layer is where we capture embeddings\n",
    "# Output = x*W1+b1\n",
    "\n",
    "W1=tf.Variable(tf.random_normal([vocab_size,EMB_DIM]),name='W1')\n",
    "b1=tf.Variable(tf.random_normal([EMB_DIM]),name='b1')\n",
    "\n",
    "hidden_layer = tf.add(tf.matmul(x,W1),b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'W1:0' shape=(7, 5) dtype=float32_ref>,\n",
       " <tf.Variable 'b1:0' shape=(5,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Add:0' shape=(?, 5) dtype=float32>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1,b1,hidden_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following layer is for predictions output/target layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2=tf.Variable(tf.random_normal([EMB_DIM,vocab_size]),name='W2')\n",
    "b2=tf.Variable(tf.random_normal([vocab_size]),name='b2')\n",
    "\n",
    "prediction_layer = tf.nn.softmax(tf.add(tf.matmul(hidden_layer,W2),b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'W2:0' shape=(5, 7) dtype=float32_ref>,\n",
       " <tf.Variable 'b2:0' shape=(7,) dtype=float32_ref>,\n",
       " <tf.Tensor 'Softmax:0' shape=(?, 7) dtype=float32>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2,b2,prediction_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  [1.6689411 1.9423704 1.9277214 2.120633  2.1204474 1.8962407 1.947509\n",
      " 2.085531  1.5721763 2.02001   2.085531  1.947509  2.02001   1.5721763\n",
      " 2.0272338 2.120633  2.1204474 2.0243533 2.0755103 2.0789943 1.8163263\n",
      " 1.9642167 2.1202397 2.120633  2.0243533 1.8997399 1.947509  1.9997978\n",
      " 1.7859854 2.0789943 1.942912  1.5421512 2.149963  2.1553357]\n",
      "loss :  [1.6157395 1.6163065 1.9125249 2.1315145 2.13151   2.1650352 1.1660149\n",
      " 2.1652753 1.6162401 1.615845  2.1652753 1.1660149 1.615845  1.6162401\n",
      " 2.1157358 2.1315145 2.13151   1.3512425 2.164024  1.1711426 1.6158632\n",
      " 1.6162493 2.1315145 2.1315145 1.3512425 2.1651595 1.1660149 2.165123\n",
      " 2.1652598 1.1711426 2.1571198 2.1640146 1.16586   2.1653147]\n",
      "loss :  [1.615851  1.6161157 1.9121633 2.1315277 2.131525  2.1652405 1.1656892\n",
      " 2.1653562 1.616073  1.6159099 2.1653562 1.1656892 1.6159099 1.616073\n",
      " 2.1158485 2.1315277 2.131525  1.3512403 2.1646028 1.1687679 1.6159085\n",
      " 1.6160868 2.1315277 2.1315277 1.3512403 2.1653085 1.1656892 2.1652884\n",
      " 2.165351  1.1687679 2.1605272 2.1646    1.1656203 2.1653733]\n",
      "loss :  [1.6158851 1.6160568 1.9120487 2.1315317 2.1315298 2.1653056 1.1655899\n",
      " 2.1653807 1.6160235 1.6159277 2.1653807 1.1655899 1.6159277 1.6160235\n",
      " 2.115884  2.1315317 2.1315298 1.3512399 2.164828  1.1678449 1.6159217\n",
      " 1.6160376 2.1315317 2.1315317 1.3512399 2.1653523 1.1655899 2.1653388\n",
      " 2.1653779 1.1678449 2.1618655 2.1648269 1.1655477 2.1653914]\n",
      "loss :  [1.6159009 1.6160287 1.9119934 2.1315336 2.131532  2.1653376 1.1655426\n",
      " 2.1653924 1.6160004 1.6159356 2.1653924 1.1655426 1.6159356 1.6160004\n",
      " 2.1159012 2.1315336 2.131532  1.3512393 2.164952  1.1673384 1.6159278\n",
      " 1.6160141 2.1315336 2.1315336 1.3512393 2.1653726 1.1655426 2.1653626\n",
      " 2.1653905 1.1673384 2.1626039 2.1649513 1.1655132 2.1654   ]\n",
      "loss :  [1.6159111 1.6160108 1.9119608 2.131535  2.1315336 2.165356  1.1655154\n",
      " 2.165399  1.6159887 1.6159382 2.165399  1.1655154 1.6159382 1.6159887\n",
      " 2.115911  2.131535  2.1315336 1.3512393 2.1650317 1.1670139 1.6159317\n",
      " 1.6159999 2.131535  2.131535  1.3512393 2.1653843 1.1655154 2.1653762\n",
      " 2.1653976 1.1670139 2.163078  2.1650312 1.1654931 2.1654048]\n",
      "loss :  [1.6159179 1.6159995 1.9119391 2.1315355 2.1315343 2.165368  1.1654978\n",
      " 2.1654036 1.6159804 1.6159408 2.1654036 1.1654978 1.6159408 1.6159804\n",
      " 2.1159177 2.1315355 2.1315343 1.3512392 2.1650872 1.1667867 1.6159344\n",
      " 1.6159906 2.1315355 2.1315355 1.3512392 2.165392  1.1654978 2.1653852\n",
      " 2.1654027 1.1667867 2.163411  2.165087  1.16548   2.165408 ]\n",
      "loss :  [1.6159227 1.6159914 1.9119246 2.1315365 2.1315353 2.1653767 1.1654855\n",
      " 2.1654067 1.6159749 1.615942  2.1654067 1.1654855 1.615942  1.6159749\n",
      " 2.115922  2.1315365 2.1315353 1.351239  2.1651287 1.1666179 1.6159364\n",
      " 1.6159841 2.1315365 2.1315365 1.351239  2.165397  1.1654855 2.1653912\n",
      " 2.1654058 1.1666179 2.1636586 2.1651285 1.165471  2.16541  ]\n",
      "loss :  [1.6159257 1.6159858 1.9119129 2.1315365 2.1315355 2.1653829 1.1654767\n",
      " 2.1654088 1.6159713 1.6159427 2.1654088 1.1654767 1.6159427 1.6159713\n",
      " 2.1159256 2.1315365 2.1315355 1.3512391 2.165161  1.166487  1.6159377\n",
      " 1.6159792 2.1315365 2.1315365 1.3512391 2.1654007 1.1654767 2.1653957\n",
      " 2.1654081 1.166487  2.163851  2.1651607 1.1654643 2.165412 ]\n",
      "loss :  [1.6159272 1.615982  1.9119043 2.131537  2.131536  2.1653876 1.1654698\n",
      " 2.1654105 1.6159672 1.6159447 2.1654105 1.1654698 1.6159447 1.6159672\n",
      " 2.1159282 2.131537  2.131536  1.3512391 2.1651864 1.1663826 1.6159385\n",
      " 1.6159757 2.131537  2.131537  1.3512391 2.1654034 1.1654698 2.165399\n",
      " 2.16541   1.1663826 2.164004  2.1651862 1.1654592 2.1654131]\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction_layer,labels=y)\n",
    "\n",
    "model = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "iters = 10000;\n",
    "\n",
    "for i in range(iters):\n",
    "    sess.run(model,feed_dict={x:x_train,y:y_train})\n",
    "    if i%1000 ==0 :\n",
    "        print('loss : ',sess.run(loss,feed_dict={x:x_train,y:y_train}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W1 contains our vectors that represent our words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.482476   -0.75052404 -0.6933675   1.292055   -1.4003232 ]\n",
      " [ 0.71176565 -1.5925647   0.75685596  2.5247107  -2.8285625 ]\n",
      " [ 3.1941679   0.9376117  -0.6940783  -0.83478236 -1.2904923 ]\n",
      " [ 3.34155    -0.6041374  -1.4217522   0.46607158  0.11367685]\n",
      " [ 2.9614196  -0.5742509  -1.6295215   0.34522247 -1.6055583 ]\n",
      " [ 1.5724167   0.7099254  -2.3266797   1.0125198  -2.0110402 ]\n",
      " [ 5.14285     0.8616059   0.39767027  1.3481035  -0.61935145]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(W1+b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am just curious to see if these vectors are orthogonal to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.083918\n",
      "14.823854\n",
      "16.860641\n",
      "17.529686\n",
      "1.7976284\n",
      "3.1196206\n",
      "7.202064\n",
      "10.558066\n",
      "11.835638\n",
      "12.537818\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    for j in range(i+1,5):\n",
    "        print(np.dot(sess.run(W1+b1)[i],sess.run(W1+b1)[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No they aren't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.482476   -0.75052404 -0.6933675   1.292055   -1.4003232 ]\n"
     ]
    }
   ],
   "source": [
    "vectors = sess.run(W1+b1)\n",
    "\n",
    "print(vectors[word2int['king']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.482476  , -0.75052404, -0.6933675 ,  1.292055  , -1.4003232 ],\n",
       "       [ 0.71176565, -1.5925647 ,  0.75685596,  2.5247107 , -2.8285625 ],\n",
       "       [ 3.1941679 ,  0.9376117 , -0.6940783 , -0.83478236, -1.2904923 ],\n",
       "       [ 3.34155   , -0.6041374 , -1.4217522 ,  0.46607158,  0.11367685],\n",
       "       [ 2.9614196 , -0.5742509 , -1.6295215 ,  0.34522247, -1.6055583 ],\n",
       "       [ 1.5724167 ,  0.7099254 , -2.3266797 ,  1.0125198 , -2.0110402 ],\n",
       "       [ 5.14285   ,  0.8616059 ,  0.39767027,  1.3481035 , -0.61935145]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queen'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2word[np.argmax(x_train[-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.14285   ,  0.8616059 ,  0.39767027,  1.3481035 , -0.61935145],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[word2int['queen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "vectors = model.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "normalizer = preprocessing.Normalizer()\n",
    "vectors =  normalizer.fit_transform(vectors, 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king 0.76039666\n",
      "is 0.16597266\n",
      "he 0.2252261\n",
      "she 0.95272195\n",
      "royal -0.894619\n",
      "the -0.8210183\n",
      "queen -0.11043813\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAESCAYAAADJ+2ORAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13888b7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "for word in words:\n",
    "    print(word, vectors[word2int[word]][1])\n",
    "    ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
