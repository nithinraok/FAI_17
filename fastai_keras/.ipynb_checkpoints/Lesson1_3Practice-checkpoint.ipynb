{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practising previous lessons on dog breed Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../dogbreed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mtest\u001b[m\u001b[m/      \u001b[34mtrain\u001b[m\u001b[m/     \u001b[34mtrain_all\u001b[m\u001b[m/ \u001b[34mvalid\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiveFiles = !ls ../dogbreed/train/affenpinscher/*.jpg | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,json\n",
    "import cv2\n",
    "from IPython.display import Image\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Dense,Flatten,BatchNormalization,Lambda\n",
    "from keras.layers.convolutional import Conv2D,ZeroPadding2D,MaxPooling2D\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import  ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imgsize=224;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAB9AIkDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDudlJsqbbQVr17nORbaXZUgXtRtouBHtAFMZkAzzjuQM1He6jZWC7rq4SIH+8etcjr3im3CEWV0wY9Ch5P61MpqKuxpXOqe6tyhIlU46jdg1lprkCTtGZBhSFwxzjI4P58flXm8WpyzO8kkr7mPJJwailv3SfIc7s7T6VzvE67GqpnrK6lGbJpVI+Zm2YPvgVfth+6XJOcc/WvJrbXZoY9iMCynIZz8qe/168VOni25R1Muozn2RgAfwxinGvF7idNnrIFOC1yWi+MLKaJPtUxjPRpJDxXXW80VzEJYJFkRujI24fnWvMmrozasKF9qXbUgSneWCKOYRmXtnbSI+I8SsN2UcxsffI/rXEarcCw8QQXCbpbqA/v4XbB45B3cZzn9a7PVYpYoi8WyZlORG+7f0wQGHTg965fWLY3GmtMbSBEVysYADsjsV3BnH8OWH61zVn2N4FrwxHNMtzquqWTvNLKzxTEgqir8oRR1Azurd/ttP8Anmn/AH03+FUNMWbTtFkjnubaby5jHGiZLITJtCg9GXrjge9dN5Uv98/9+T/jVRaS1Ik9SLZQENXAqmgogGTgAd605ybFURn0qK5LxQsUQu/8K1eRUkVXQhlYblYHII9ar35eO1kMLgTbSEz03dj+FLnDlPGPHXmx6i0d3cLLckZZEwQn+Fc00hMARdxatnxR5ceqS2lrGSsbFWkYZeV8/M7N9azMixt9rDc79a5asryNorQbG8sabZMDvjuKhnkw3mD5geuKWIGeVd7sF5yUHTimiF5G2jhsc1kXqRo7SYRnIBPA/rUk8DIoAbcByDUDL8/ysQR+dWZQ7RKN7btv3D060xDYmkVem5e+OortPAMe+4322qeTcDP7rcfmX129G+lcRCzbgVGT93Hr7Vr+F3KeIbVQ7Rs0yqjg42sTgZ/Hj8a0hKzJktD3+23vbo0oUOV+bb0z7U6R44lDSOqAkLljjk9BRag/ZVZ8jC55HNcN4p8WNI76fHbxm3MqGO4EmWbADBgB67hitpSsZKNzo7l7uOZjE8ZVZMuruUbaRyVfnpxxjj1rkvFGl31netc2sB/04sXEJVlbJC+2W5U5xk5NbWg38t39js7kJDarCeLqTdJI+WGc9/4h7Y+lUtf094IJnhmV5ocMcPnKq25hnt91eKyqSTVzSC1Fs7CKJLGR2Jka4fz0wudqsRhdg79cDgheneuj/tHS/wDnu/8A37P+FZOgpI/iNrW6iYLZxPNGAhCK0j+/oOB9TXV/Zof7rfmauMlYmV0yjHq1k9it6ZjHC77A0iMh3ZxjawBrN8ValHb2aRRyEN5uHKZJX5c4x3JBrm/EOtyavdjEbRww5VAX3buPvN2B7VmpPMYSkkrMGAyGGR04Xn0qZVEiox6nTaf4m+wxJbuiuu9cbGA2j+JQD29Oasaxr8cYdo2k54TcoUM3t7YJyfpiuGkuPJKHIYtIq+nXvS3M7yI3myNIV5z2HrWXtmaciKGspG9y1wUxucuc+/QVz88LXNyqqMg9fYVr6tI78YOF4655rItnYz4HLZ+UelRdvUa7FhoFjUxxRmWToAOlQSJ5b7NgMsinIXkYqe5uFgRYkH71htZt3T1xUtm0QmZZEUtsySe3TFK42kZ8KxpcZljbJPBxxmrU7oW3FSwHZePxxTbm5E2McKe3bOagRiWMbnO5SyZphsQPtifchJV+cHsR2rodE2Xd9FLKi72Kr5inb8w+6W9/549a5qUlAYyc/NkH8P8A9VbPh+58tyrYKOuDn+Fu3NaRdiGrnsepa9p8tjdWss1xG0cgVHtyA+Qu9WHbGRtwc+9efXO26vJFjiaOKM7okJyVHXr7E1LC53s5DEAAKRzu+lReYBc+Y29nx0AGAPz61lKo3sXGNjZ0q5R7iF72FpZYp1Z5kYB0TO4Zz975geR0Xr2q1avFeXdw58199tMzHnI3YwScY6npXOyXMUjgSIwVcNleD7ZrYsHD6RqTp57tGqDKuULL82cnuPb2qZSckioq1yawu7q41S3hD+T5cTLC+S/mOG3ZbefXueM9K3dnjP8A56y/98J/8TXEujO0KIjNsO47myW4AH6YrR+2X3v/AN9t/jVxq6EyhqYq3PmKwk5BO6pBIGIKk/L78VXOk6ojrGbGcsemFzUMayO7I6tlM7wBz6YI9acoslMddSEvAGTH70H68Gp0z5QLEsv6D6mqjiWaaE+U2xX3F9rEfdPWnS3CxFf4sgjb3yGIqOUdzP1WXYCAQWzzWbZkiXzF5YKav6tFKjjzEwzDPNZkTtBKoBFVYOosC/ab9Cx+Vn25PpVlXG2ZweRnP50yMxmdijhfmDAH9agu2eG7bAABbI29MH09qA2NCKzSVIVDYW5B2N6NVW5tntZYi/DR43D8eadBevHaW1vziO43p6jkcUardCa4Z0X+Ljmkk7jbVijdqPtDKv8ACMVf0VVM2xujdRWcPmcsx5PU1qaQ2ydWC7varexCd2dRMymIKGYfKPu/eYY/QVWeUBQCjLIvQgY7dvzq0lwu5okiG+VMs2zOBVS5eNnZdjCT72XXB2/j0rCxqN8rehKyHdj7xPQ+ldL4fLyaNrOUUrHGihUGR0b5s/XtXLII5Ll124B4Ozp7VYtLiW3SVEdlVxggHAbr+dVy3JTtqOQK1u104bzIeGJzyrZAPX1qTzLX/nu360y3KvBcI8h2vDtAPPKsD+HGak8i0/55T/l/9apsVdnpMVja3IYRyOjKCdmwZfH909zT5dHszbySx28aSxr8xuFBc+3HT2rVk0aKTdMPMR3UkxhyE3e+3+lRrbtG5U20UZ7Ejd5mPX+ldTlcxRzkcMdzujhZTnKlN3H0qFfA8NrA91FYRmRjuVHJdvc89MV0t5pVrcOrqiF/LIC7VUAc/MO459KqWmjXqXEayXETxMpAWSQs6+u3kjFNyCx5B4nTbfSgsWKtkt6GuZlI3Hk5r0n4jaY+nsplKlp/myMZOP6V5xInJ29MVDtcZBnng470+WZ3UROdwX7pbtTAGzkdaQLlsUgJEkZGLrgN0Q/3ajIJ5P51KI/lPemhSuQfxBoAjANaem+Y06iMkE+lUwgB/CtjwwSNbgVN24t8oXqae4I6SWxuGmdoPMVTAmcEkd/0yDUFhol28i+ejAMm0jBJ2nvXo1vp8kYLpalvMRVz5OflBJAGenJNXYRqCQu0dhCckBj5PzEf7uf6VPs2VzI4FfCcuWmCsh3BgqMF47dTWdqGly2I86WNlDKu4Yxlup/z7V6XJaXPnLPJZ26+RGMABgFVu2AcHpWZqulRamiR3CyQlSxZk43gjGMHpj2ojCVwco2PPnsrhYHkiQCMQ7zk8/p+P5Uz+0W/55J/33/9avR7HS7S2txaNGssUkfksX+ZipGDj0PuKi/4Q3wt/wA+bf8Af9//AIqjkkLmR0kl9dLAZBbAK42qCDuArDt5/EreIXjdjFpq2+5WJ+Yvkevfr7YrVS3nuv8AlvGAjbmSJyw2+3eriW0Bgd42aRvu+hJ96u66CMeSVwqb8tjJ37uSPSo1lKuvl/KV+YZbGPxq8dIuSqC5nhgUZC87uf0qNrSOA/6Qs0sQ+XzETCH34q1KIHB/ECWW8uY3lDMURVGSCMdQM+/WvPZkeNsuMbuleqeJba3uYYYbeJwyOWeR+d/p/KuJ1uwEPozAnJHP4ZqJR10A5srgZPHoBUY5DHHTmnswMnXHoBwBQY2Vjt6VACLcOvDKGX3FLLIjBSikHvTljZFzwQe1MKBxxx7UwHDkhvWrtgxS9gdNwZXHKcEH2plhDvbypFyGBCk+tTwJt1KGMISd2MA9fp70wPetD1TT/wCz4gJpzIQNxnUlmP4cU+bV51umKIrJnC5XnH1rL0COzvLWKRJFjkZOVb7xx/sitdbGSS1aOF13Mo3O6nv/AHaqyW4D4tSkuHzHGAwUgqx+U/8A181aQQyqJ54VDMvzLIQ238KyrTT18zbI05mTqNvyYz1wa0GtocMxRTICdoVQNx9MUml0CwqTWFu7eVEE/wBpEyv14qrm1/5623/ftqnSweW43yYEIHC4xk/QGrn2P/b/APHRSugOej1G681ktMR84GVXn9KW0h1B7ySaeW6kLsBs52LjuoPA9c099Z0+GdopYyuz7r7Awb8O1Ca7vuPJtrhV81sx7kymT/CT1Bqnboh6k128l4REiN50fBz/ABZp6SXUKkSMEBXAVR07VJHqcLNl7mEHqxaIqc/Wmz3Cs52XW5m4+Y7VNJAhsnh4XSBpJSjHllHKt6ZrnfEPhfybGR4Y2kco/GBgf4CuoW+khcJLL8qYGF2kNnpzVXUr1bu1ntH/AHYdCAXRic+pA7fjTvLqJI+drmFoLiRCfmRtpxzVtNl5a796LJGm0p3bHeoNRRE1C4WNw6K7BWxjcuTg1NpSxfZ5pHDZRTyFBwe3XpUgMi2BWRz/AAH8+1V0PO8nJ7CnyDEWRUEGWnUZxlwOaQ2djZaVE+nGXz8NEhYBhjnB6flWdoj2txraRXcbGObCq6dY2yOa9O0fTrWXw1H/AGhb7WEeWLQ/Mx6Bc9+a8rRJdG8TrHcI0RgudrKxxtBP+BpjPctN0CS1WO3mIkhTJ3K+O3B9a1fLsrEIC4hGQqqXIDHp+NQ2t7EY1heUswjALAYHTsetVL69teYJXecRtyythk9R6NQ22TY2mkViUYMnOA3TJ9qoyW88LKbR0coGLLIO/tjv1pqavYRWoSCVSEGNrE5xVG41dHIkikKuOcbgw/4D6UrMLE7XtxcwKsSvbSJklW+TzD6Lu/rSbdW/vT/kn+NQr4iYKUmt/NJHC8Cmf8JIn/QLf/v4tO3kByd67mdmfcOTyabbpPcSCO2jeVjxhFLfnXbaVpkEyiSZRJ1+VhkVuIiouFVVHoBircraITOXsvDF6EX7RdiPIBZEy2PUZ/Kp4dBuVu2DzLIgH3mHP5VvROzSPk8DoKY0xCM4UbvWoc5AYw8yxvmthEJYyBsb5VwfwFZniebUrDSphaRCSXCr+/AWPnOSG/8AZe9dTaRJIPPcZYn8qknVJi1tLGHjkTDA9weMUuYdz5fnWaWeV7jcGLEkAY5NLa212ySeVayOv8bqhO38a+hpfBmhCaOSLT4EkLDLMu7OAccE1dW1htjBHHFGqq5AAQDHbj04NF0CPmy7t3to4S5QeahZQHDEDOOcdKjsozPfxRoV3M4xuOBmvU/F3w505NO1bX1u5llj3MsIVQgx9BnmvKDEI2JDEkc5+hpoLntFrrF8lmsCSqJlXIQYZUwOPbjHSuF8S6dcXV1LeRRG6mnJZ3cgEN/ujA5rW0B5JNKhmeQlnTnjHtV9EXzhkZA7VajdXG2N0T+3NNsY49TlPmBVEKn70aDoCa1Y7ia4QxsQQzZ5Pf1qs1w1wS78knuc1PYoXYAMVy2049DmqSVhXY+NId+JHcKFPKLnmrPmRGHEHynb82TzXSQeG7H7K0bAszE/Oeorj5YxHMyZztOM+uDSi7sLkzRFFV9+XIz97pUO9/7361Ih+XGKf5I/vGrsB//Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(fiveFiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen=ImageDataGenerator(featurewise_center=False,\n",
    "                           featurewise_std_normalization=False,\n",
    "                           horizontal_flip=True,\n",
    "                          rescale=1./255,width_shift_range=0.1,\n",
    "                          height_shift_range=0.1,\n",
    "                           shear_range=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9022 images belonging to 120 classes.\n",
      "Found 1200 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "batches=dataGen.flow_from_directory(f'{path}/train',target_size=(Imgsize,Imgsize),\n",
    "                                   batch_size=32)\n",
    "val_batches=dataGen.flow_from_directory(f'{path}/valid',target_size=(Imgsize,Imgsize),\n",
    "                                   batch_size=32)\n",
    "#test_batches=dataGen.flow(f'{path}/test',                               batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(model,filters,num_layers):\n",
    "    for i in range(num_layers):        \n",
    "        model.add(ZeroPadding2D((1,1),data_format='channels_first'));\n",
    "        model.add(Conv2D(filters,(3,3),activation='relu',data_format='channels_first'));\n",
    "        \n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCBlock(model,num_layers=4096):\n",
    "    model.add(Dense(num_layers,activation='relu'));\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_mean=np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "def vgg_preprocess(x):\n",
    "    x=x-vgg_mean;\n",
    "    return x[:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Lambda(vgg_preprocess,input_shape=(3,224,224)))\n",
    "ConvBlock(model,64,2)\n",
    "ConvBlock(model,128,2)\n",
    "ConvBlock(model,256,3)\n",
    "ConvBlock(model,512,3)\n",
    "ConvBlock(model,512,3)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "FCBlock(model)\n",
    "FCBlock(model)\n",
    "model.add(Dense(1000,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file;\n",
    "weigths_path=get_file('Vgg16.h5','http://files.fast.ai/models/vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weigths_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers: layer.trainable = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1000,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(120,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_2 (Lambda)            (None, 3, 224, 224)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 3, 226, 226)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 64, 226, 226)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 64, 114, 114)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPaddi (None, 128, 114, 114)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPaddi (None, 128, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPaddi (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPaddi (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPaddi (None, 256, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPaddi (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPaddi (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 120)               120120    \n",
      "=================================================================\n",
      "Total params: 138,477,664\n",
      "Trainable params: 4,217,120\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281.9375"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9022/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1200/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_generator() missing 1 required positional argument: 'steps_per_epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-348f3086952d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit_generator() missing 1 required positional argument: 'steps_per_epoch'"
     ]
    }
   ],
   "source": [
    "model.fit_generator(batches,steps_per_epoch=280,epochs=5,validation_data=val_batches,validation_steps=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
