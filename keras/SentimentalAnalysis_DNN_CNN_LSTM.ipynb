{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Input,Embedding,Dropout,Conv2D,BatchNormalization,Flatten,Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import sklearn\n",
    "import pickle\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.layers import Conv1D,MaxPooling1D,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../../data/aclImdb/'\n",
    "\n",
    "from keras.datasets import imdb\n",
    "idx=imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_arr=sorted(idx,key=idx.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'a', 'of', 'to', 'is', 'br', 'in', 'it', 'i']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v:k for k,v in idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(path+'imdb_full.pkl', 'rb')\n",
    "(x_train, labels_train), (x_test, labels_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([idx2word[ind] for ind in x_train[0]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing vocab size to 5000 and setting the other vocabs to comman vocab of vocab_size-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "\n",
    "trn = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_train]\n",
    "test = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2493, 10, 237.71364)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = list(map(len,trn))\n",
    "max(lens),min(lens),np.mean(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making every trn idx consistent and choosing max len and padding sequences less than this length to zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 500\n",
    "\n",
    "trn = sequence.pad_sequences(trn, maxlen=seq_len, value=0)\n",
    "test = sequence.pad_sequences(test, maxlen=seq_len, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32, input_length=seq_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               1600100   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,760,201\n",
      "Trainable params: 1,760,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/6\n",
      "25000/25000 [==============================] - 13s 528us/step - loss: 0.4499 - acc: 0.7642 - val_loss: 0.2889 - val_acc: 0.8794\n",
      "Epoch 2/6\n",
      "25000/25000 [==============================] - 13s 527us/step - loss: 0.1843 - acc: 0.9316 - val_loss: 0.3368 - val_acc: 0.8634\n",
      "Epoch 3/6\n",
      "25000/25000 [==============================] - 13s 534us/step - loss: 0.0624 - acc: 0.9806 - val_loss: 0.4037 - val_acc: 0.8657\n",
      "Epoch 4/6\n",
      "25000/25000 [==============================] - 13s 537us/step - loss: 0.0132 - acc: 0.9975 - val_loss: 0.5135 - val_acc: 0.8656\n",
      "Epoch 5/6\n",
      "25000/25000 [==============================] - 14s 541us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5809 - val_acc: 0.8656\n",
      "Epoch 6/6\n",
      "25000/25000 [==============================] - 14s 545us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.6208 - val_acc: 0.8658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14e892eb8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,epochs=6,batch_size=64,validation_data=(test,labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = Sequential()\n",
    "model_conv.add(Embedding(vocab_size,32, input_length=seq_len))\n",
    "model_conv.add(Dropout(0.2))\n",
    "model_conv.add(Conv1D(64,5,padding='same',activation='relu'))\n",
    "model_conv.add(Dropout(0.2))\n",
    "model_conv.add(MaxPooling1D())\n",
    "model_conv.add(Flatten())\n",
    "model_conv.add(Dense(100,activation='relu'))\n",
    "model_conv.add(Dropout(0.7))\n",
    "model_conv.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 500, 64)           10304     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               1600100   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,770,505\n",
      "Trainable params: 1,770,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 43s 2ms/step - loss: 0.4981 - acc: 0.7208 - val_loss: 0.2765 - val_acc: 0.8880\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 40s 2ms/step - loss: 0.2658 - acc: 0.8990 - val_loss: 0.2568 - val_acc: 0.8938\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 41s 2ms/step - loss: 0.2133 - acc: 0.9204 - val_loss: 0.2761 - val_acc: 0.8860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x151defc18>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv.fit(trn,labels_train,epochs=3,batch_size=64,validation_data=(test,labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential();\n",
    "lstm_model.add(Embedding(vocab_size,32,input_length=seq_len))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(LSTM(100,activation='tanh'))\n",
    "lstm_model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 222s 9ms/step - loss: 0.4681 - acc: 0.7685 - val_loss: 0.3346 - val_acc: 0.8588\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 212s 8ms/step - loss: 0.2849 - acc: 0.8873 - val_loss: 0.2994 - val_acc: 0.8751\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 213s 9ms/step - loss: 0.2463 - acc: 0.9046 - val_loss: 0.3234 - val_acc: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159afe5f8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(trn,labels_train,epochs=3,batch_size=64,validation_data=\n",
    "              (test,labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
